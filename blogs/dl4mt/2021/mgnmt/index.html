<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Mirror-Generative Neural Machine Translation | MLNLP Blog</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/blog/icon48.png">
    <link id="echarts-lib" rel="prefetch" href="https://cdn.bootcss.com/echarts/4.2.1/echarts.min.js">
    <meta name="description" content="Blogs on NLP, Machine Learning, Data Mining, and other AI related topics">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="/blog/assets/css/0.styles.0a66d5ca.css" as="style"><link rel="preload" href="/blog/assets/js/app.1e8a9a71.js" as="script"><link rel="preload" href="/blog/assets/js/3.9239b0cb.js" as="script"><link rel="preload" href="/blog/assets/js/1.41e97d18.js" as="script"><link rel="preload" href="/blog/assets/js/29.ce874456.js" as="script"><link rel="prefetch" href="/blog/assets/js/10.6cecc18b.js"><link rel="prefetch" href="/blog/assets/js/11.8321927d.js"><link rel="prefetch" href="/blog/assets/js/12.7bb89653.js"><link rel="prefetch" href="/blog/assets/js/13.228c135d.js"><link rel="prefetch" href="/blog/assets/js/14.6f3d3721.js"><link rel="prefetch" href="/blog/assets/js/15.902cc4e7.js"><link rel="prefetch" href="/blog/assets/js/16.7c1756b4.js"><link rel="prefetch" href="/blog/assets/js/17.3c14211f.js"><link rel="prefetch" href="/blog/assets/js/18.07555720.js"><link rel="prefetch" href="/blog/assets/js/19.dd6a25bb.js"><link rel="prefetch" href="/blog/assets/js/20.a1d56abd.js"><link rel="prefetch" href="/blog/assets/js/21.2d1b9a16.js"><link rel="prefetch" href="/blog/assets/js/22.97193d37.js"><link rel="prefetch" href="/blog/assets/js/23.90c6c552.js"><link rel="prefetch" href="/blog/assets/js/24.f101ecef.js"><link rel="prefetch" href="/blog/assets/js/25.8f9e4202.js"><link rel="prefetch" href="/blog/assets/js/26.14ae020f.js"><link rel="prefetch" href="/blog/assets/js/27.aafaf639.js"><link rel="prefetch" href="/blog/assets/js/28.e0cde896.js"><link rel="prefetch" href="/blog/assets/js/4.a2131c77.js"><link rel="prefetch" href="/blog/assets/js/5.abccaae4.js"><link rel="prefetch" href="/blog/assets/js/6.ec430a6b.js"><link rel="prefetch" href="/blog/assets/js/7.17e26a65.js"><link rel="prefetch" href="/blog/assets/js/8.bcb7713a.js"><link rel="prefetch" href="/blog/assets/js/9.39d9de69.js">
    <link rel="stylesheet" href="/blog/assets/css/0.styles.0a66d5ca.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-1156296a><div data-v-1156296a><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-1156296a data-v-1156296a><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-4e82dffc data-v-1156296a data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>MLNLP Blog</h3> <p class="description" data-v-4e82dffc data-v-4e82dffc>Blogs on NLP, Machine Learning, Data Mining, and other AI related topics</p> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>Lei Li</span>
            
          <span data-v-4e82dffc>2016 - </span>
          2022
        </a></span></div></div> <div class="hide" data-v-1156296a><header class="navbar" data-v-1156296a><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/blog/" class="home-link router-link-active"><img src="/blog/logo.png" alt="MLNLP Blog" class="logo"> <span class="site-name">MLNLP Blog</span></a> <div class="links"><!----> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/categories/ST/" class="nav-link"><i class="undefined"></i>
  ST
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/DL4MT/" class="nav-link"><i class="undefined"></i>
  DL4MT
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/MT/" class="nav-link"><i class="undefined"></i>
  MT
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/NLG/" class="nav-link"><i class="undefined"></i>
  NLG
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/NLP/" class="nav-link"><i class="undefined"></i>
  NLP
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/IE/" class="nav-link"><i class="undefined"></i>
  IE
</a></li></ul></div></div><div class="nav-item"><a href="/blog/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/blog/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/lileicc" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  lilei
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-1156296a></div> <aside class="sidebar" data-v-1156296a><div class="personal-info-wrapper" data-v-828910c6 data-v-1156296a><img src="/blog/avatar.png" alt="author-avatar" class="personal-img" data-v-828910c6> <h3 class="name" data-v-828910c6>
    Lei Li
  </h3> <div class="num" data-v-828910c6><div data-v-828910c6><h3 data-v-828910c6>19</h3> <h6 data-v-828910c6>Articles</h6></div> <div data-v-828910c6><h3 data-v-828910c6>33</h3> <h6 data-v-828910c6>Tags</h6></div></div> <ul class="social-links" data-v-828910c6></ul> <hr data-v-828910c6></div> <nav class="nav-links"><div class="nav-item"><a href="/blog/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/categories/ST/" class="nav-link"><i class="undefined"></i>
  ST
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/DL4MT/" class="nav-link"><i class="undefined"></i>
  DL4MT
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/MT/" class="nav-link"><i class="undefined"></i>
  MT
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/NLG/" class="nav-link"><i class="undefined"></i>
  NLG
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/NLP/" class="nav-link"><i class="undefined"></i>
  NLP
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/IE/" class="nav-link"><i class="undefined"></i>
  IE
</a></li></ul></div></div><div class="nav-item"><a href="/blog/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/blog/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/lileicc" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  lilei
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-4e82dffc data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>Mirror-Generative Neural Machine Translation</h3> <!----> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>Lei Li</span>
            
          <span data-v-4e82dffc>2016 - </span>
          2022
        </a></span></div></div> <div data-v-1156296a><main class="page"><section><div class="page-title"><h1 class="title">Mirror-Generative Neural Machine Translation</h1> <div data-v-1ff7123e><i class="iconfont reco-account" data-v-1ff7123e><span data-v-1ff7123e>Tsu-Jui Fu</span></i> <i class="iconfont reco-date" data-v-1ff7123e><span data-v-1ff7123e>11/25/2021</span></i> <!----> <i class="tags iconfont reco-tag" data-v-1ff7123e><span class="tag-item" data-v-1ff7123e>Variational Inference</span><span class="tag-item" data-v-1ff7123e>Latent Variable Model</span><span class="tag-item" data-v-1ff7123e>Semi-supervised Machine Translation</span></i></div></div> <div class="theme-reco-content content__default"><p>In general, neural machine translation (NMT) requires a large amount of parallel data (e.g., EN-&gt;CN). However, it is not easy to collect enough high-quality parallelly-paired sentences for training the translation model. On the other hand, we can capture enormous plain text from Wikipedia or news articles for each specific language. In this paper, MGNMT tries to make good use of non-parallel data and boost the performance of NMT.</p> <p><a href="https://openreview.net/pdf?id=HkxQRTNYPH" target="_blank" rel="noopener noreferrer">Paper<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p><a href="https://github.com/zhengzx-nlp/MGNMT" target="_blank" rel="noopener noreferrer">Code<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <h2 id="background-back-translation"><a href="#background-back-translation" class="header-anchor">#</a> Background (Back Translation)</h2> <p>Back Translation (BT) is a technique to boost translation performance by incorporating pseudo-inverse pairs as parallel sentences. Assuming that we are translating English (EN) into Chinese (CN), our translation goal is TM<sub>EN-CN</sub>. BT considers another TM<sub>CN-EN</sub> that translates Chinese sentences back to English. With the back-translated English sentences, BT treats the additional EN-CH sentences to further train TM<sub>EN-CN</sub>. By alternative training TM<sub>EN-CN</sub> and TM<sub>CN-EN</sub>, we can improve TM<sub>EN-CN</sub> by pseudo-parallel pairs. Although BT increases translation performance, both TM<sub>EN-CN</sub> and TM<sub>CN-EN</sub> are updated independently, which limits the effectiveness of using non-parallel sentences.</p> <img src="https://i.imgur.com/rpj2IFj.png" width="30%"> <h2 id="mgnmt"><a href="#mgnmt" class="header-anchor">#</a> MGNMT</h2> <h3 id="overview"><a href="#overview" class="header-anchor">#</a> Overview</h3> <p>MGNMT is a unified NMT framework that considers both source-target and target-source translation models (TM) with their respective language models (LM). Both TM and LM share the semantic space, making it more efficient when learning from the non-parallel corpus. In addition, LM can further improve the text quality during the decoding step of TM. Inspired by generative NMT (GNMT), MGNMT introduces a latent semantic variable z and adopts symmetry of mirror-image properties to decompose the conditional joint probability p(x, y | z):</p> <img src="https://i.imgur.com/zXfL7CY.png" width="60%"> <ul><li>(x, y): source-target language pair;</li> <li>Θ: trainable model parameters for TM and LM;</li> <li>D_xy: parallel source-target corpus;</li> <li>D_x and D_y: non-parallel monolingual corpus.</li></ul> <h3 id="parallel-training"><a href="#parallel-training" class="header-anchor">#</a> Parallel Training</h3> <p>Given a parallel corpus (x, y), MGNMT adopts stochastic gradient variational Bayes (SGVB) to obtain an approximate maximum likelihood estimate of log p(x, y):</p> <img src="https://i.imgur.com/RvtbmWh.png" width="60%"> <p>and the Evidence Lower Bound (ELBO) can be derived as:</p> <img src="https://i.imgur.com/kH82Wt1.png" width="60%"> <p>Through reparameterization, we can jointly train the entire MGNMT via gradient-based optimizations for parallel-corpus training.</p> <img src="https://i.imgur.com/XzRf5Uz.png" width="30%"> <h3 id="non-parallel-training"><a href="#non-parallel-training" class="header-anchor">#</a> Non-parallel Training</h3> <p>To utilize non-parallel corpus, MGNMT designs an interactive training method by back translation (BT). Given a sentence x<sub>s</sub> in the source language and y<sub>t</sub> in the target language, MGNMT aims at maximizing the lower bounds of their marginal distribution likelihood:</p> <img src="https://i.imgur.com/Vy7RI5F.png" width="60%"> <p>As BT, for example, MGNMT samples x from p(x | y<sub>t</sub>) as the translation result of y<sub>t</sub>, and a pseudo-parallel pair (x, y<sub>t</sub>) is produced:</p> <img src="https://i.imgur.com/6XvCgKa.png" width="60%"> <p>With the pseudo-parallel corpus from two directions, they can combine to train MGNMT:</p> <img src="https://i.imgur.com/XJMC9YW.png" width="60%"> <p>Since the latent variable comes from the shared posterior q(z | x, y; Θ), it serves as a communication bridge that boosts the BT performance in MGNMT.</p> <h3 id="decoding"><a href="#decoding" class="header-anchor">#</a> Decoding</h3> <p>MGNMT considers pre-trained LM to help obtain smoother and higher-quality translation results during decoding.</p> <img src="https://i.imgur.com/o0RpZF5.png" width="60%"> <p>Take the source-to-target translation as an example:</p> <ol><li>Sample an initialized latent variable z from the standard Gaussian prior distribution, and receives a translation result y from argmax<sub>y</sub> p(y | x, z);</li> <li>Keep re-decoding with beam search to maximize ELBO:</li></ol> <img src="https://i.imgur.com/DgsYMmF.png" width="60%"> <p>Each decoding score is determined by the x-to-y translation and the LM<sub>y</sub>, making the translated results more similar to the target language. Moreover, the reconstructed score is obtained from the y-to-x translation and LM<sub>x</sub>, further improving the translation effect upon the idea of BT.</p> <h2 id="exeperiments"><a href="#exeperiments" class="header-anchor">#</a> Exeperiments</h2> <h3 id="dataset"><a href="#dataset" class="header-anchor">#</a> Dataset</h3> <table><thead><tr><th style="text-align:center;">Dataset</th> <th style="text-align:center;">WMT14<sub>EN-DE</sub></th> <th style="text-align:center;">NIST<sub>EN-ZH</sub></th> <th style="text-align:center;">WMT16<sub>EN-RO</sub></th> <th style="text-align:center;">IWSLT16<sub>EN-DE</sub></th></tr></thead> <tbody><tr><td style="text-align:center;">Paralel</td> <td style="text-align:center;">4.50M</td> <td style="text-align:center;">1.34M</td> <td style="text-align:center;">0.62M</td> <td style="text-align:center;">0.20M (TED)</td></tr> <tr><td style="text-align:center;">Non-parallel</td> <td style="text-align:center;">5.00M</td> <td style="text-align:center;">1.00M</td> <td style="text-align:center;">1.00M</td> <td style="text-align:center;">0.20M (NEWS)</td></tr></tbody></table> <p>MGNMT considers WMT16<sub>EN-RO</sub> as low-resource translation and IWSLT16<sub>EN-DE</sub> of TED talk for cross-domain translation. Both WMT14<sub>EN-DE</sub> and NIST<sub>EN-ZH</sub> are for the general resource-rich evaluation. Specifically, all models are trained using parallel data from TED and non-parallel data from NEWS for cross-domain translation.</p> <h3 id="quantitative-results"><a href="#quantitative-results" class="header-anchor">#</a> Quantitative Results</h3> <img src="https://i.imgur.com/bqJFmCn.png" width="60%"> <p><b>Resource-low Translation.</b> Firstly, as for the resource-low scenario (WMT16<sub>EN-RO</sub> and IWSLT16<sub>EN-DE</sub>), MGNMT slightly surpasses the competitive baselines (<i>e.g.,</i> 33.9 BLEU on WMT16<sub>RO-EN</sub> and 33.6 BLEU on TED<sub>DE-EN</sub>). If incorporating non-parallel data, MGNMT gains a significant improvement (<i>e.g.,</i> +5.2% BLEU on TED<sub>EN-DE</sub> and +5.9% on NEWS<sub>DE-EN</sub>), which outperforms all other baselines that also use non-parallel corpus.</p> <img src="https://i.imgur.com/JntnTEI.png" width="60%"> <p><b>Resource-rich Translation.</b> Similar results can be found in resource-rich scenarios. MGNMT performs better than GNMT with only the parallel corpus (<i>e.g.,</i> 31.4 BLEU on WMT14<sub>DE-EN</sub> and 40.42 BLEU on NIST<sub>EN-ZH</sub>) and further boosts the translation quality with the aid of non-parallel data (<i>e.g.,</i> 30.3 BLEU on WMT14<sub>EN-DE</sub> and 49.05 BLEU on NIST<sub>ZH-EN</sub>).</p> <h3 id="ablation-study"><a href="#ablation-study" class="header-anchor">#</a> Ablation Study</h3> <img src="https://i.imgur.com/tzEeu7u.png" width="30%"> <p><b>Effectiveness of Language Model during Decoding.</b> Incorporating a pre-trained language model (LM) during decoding is an intuitive method to improve decoding quality. However, such simple interpolation (LM-FUSION) over NMT and external LM only brings out mild effects. In contrast, a natural integration adopted in MGNMT is essential to address the unrelated probabilistic modeling issue.</p> <img src="https://i.imgur.com/tzEeu7u.png" width="30%"> <p><b>Impact of #Non-parallel Data.</b> The plot shows that with more non-parallel data involved, the translation performance keeps increasing, which demonstrates the benefit of MGNMT from data scales. Surprisingly, one monolingual side data, English, can also improve EN-GN translation under the MGNMT framework.</p> <h3 id="qualitative-examples"><a href="#qualitative-examples" class="header-anchor">#</a> Qualitative Examples</h3> <p><img src="https://i.imgur.com/vPGJ7Wo.png" width="30%"><img src="https://i.imgur.com/VQil8lK.png" width="30%"></p> <p>Without non-parallel in-domain data (NEWS), the baseline (RNMT) results in an obvious style mismatches phenomenon. Among all enhanced methods that attempt to alleviate this domain inconsistency issue, MGNMT leads to the best in-domain-related translation results.</p> <h2 id="conclusion"><a href="#conclusion" class="header-anchor">#</a> Conclusion</h2> <p>This paper presents a mirror generative NMT, MGNMT, that utilizes non-parallel corpus efficiently. MGNMT adopts a shared bilingual semantic space to jointly learn their goal and back-translated models. Moreover, MGNMT considers the learned language model during decoding, which directly improves the translation quality. One future research direction is to integrate MGNMT for fully unsupervised NMT.</p> <h2 id="reference"><a href="#reference" class="header-anchor">#</a> Reference</h2> <ul><li>Zaixiang Zheng, Hao Zhou, Shujian Huang, Lei Li, Xin-Yu Dai, and Jiajun Chen. Mirror-Generative Neural Machine Translation. ICLR 2020.</li></ul></div></section> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">2/10/2022, 11:05:57 PM</span></div></footer> <!----> <div class="comments-wrapper"><!----></div> <ul class="side-bar sub-sidebar-wrapper" style="width:12rem;" data-v-70334359><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#background-back-translation" class="sidebar-link reco-side-background-back-translation" data-v-70334359>Background (Back Translation)</a></li><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#mgnmt" class="sidebar-link reco-side-mgnmt" data-v-70334359>MGNMT</a></li><li class="level-3" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#overview" class="sidebar-link reco-side-overview" data-v-70334359>Overview</a></li><li class="level-3" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#parallel-training" class="sidebar-link reco-side-parallel-training" data-v-70334359>Parallel Training</a></li><li class="level-3" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#non-parallel-training" class="sidebar-link reco-side-non-parallel-training" data-v-70334359>Non-parallel Training</a></li><li class="level-3" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#decoding" class="sidebar-link reco-side-decoding" data-v-70334359>Decoding</a></li><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#exeperiments" class="sidebar-link reco-side-exeperiments" data-v-70334359>Exeperiments</a></li><li class="level-3" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#dataset" class="sidebar-link reco-side-dataset" data-v-70334359>Dataset</a></li><li class="level-3" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#quantitative-results" class="sidebar-link reco-side-quantitative-results" data-v-70334359>Quantitative Results</a></li><li class="level-3" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#ablation-study" class="sidebar-link reco-side-ablation-study" data-v-70334359>Ablation Study</a></li><li class="level-3" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#qualitative-examples" class="sidebar-link reco-side-qualitative-examples" data-v-70334359>Qualitative Examples</a></li><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#conclusion" class="sidebar-link reco-side-conclusion" data-v-70334359>Conclusion</a></li><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/mgnmt/#reference" class="sidebar-link reco-side-reference" data-v-70334359>Reference</a></li></ul></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="/blog/assets/js/app.1e8a9a71.js" defer></script><script src="/blog/assets/js/3.9239b0cb.js" defer></script><script src="/blog/assets/js/1.41e97d18.js" defer></script><script src="/blog/assets/js/29.ce874456.js" defer></script>
  </body>
</html>
