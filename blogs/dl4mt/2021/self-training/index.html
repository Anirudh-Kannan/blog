<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Revisiting Self-training for Neural Sequence Generation | MLNLP Blog</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/blog/icon48.png">
    <link id="echarts-lib" rel="prefetch" href="https://cdn.bootcss.com/echarts/4.2.1/echarts.min.js">
    <meta name="description" content="Blogs on NLP, Machine Learning, Data Mining, and other AI related topics">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="/blog/assets/css/0.styles.0a66d5ca.css" as="style"><link rel="preload" href="/blog/assets/js/app.6f4a53e5.js" as="script"><link rel="preload" href="/blog/assets/js/3.9b1d869a.js" as="script"><link rel="preload" href="/blog/assets/js/1.6e4b099c.js" as="script"><link rel="preload" href="/blog/assets/js/21.9965f21d.js" as="script"><link rel="prefetch" href="/blog/assets/js/10.06bf6541.js"><link rel="prefetch" href="/blog/assets/js/11.071218e0.js"><link rel="prefetch" href="/blog/assets/js/12.d4e006ef.js"><link rel="prefetch" href="/blog/assets/js/13.5a6fc967.js"><link rel="prefetch" href="/blog/assets/js/14.4ac0e772.js"><link rel="prefetch" href="/blog/assets/js/15.7db0c2fe.js"><link rel="prefetch" href="/blog/assets/js/16.b749e36c.js"><link rel="prefetch" href="/blog/assets/js/17.94611c4e.js"><link rel="prefetch" href="/blog/assets/js/18.54f03a1c.js"><link rel="prefetch" href="/blog/assets/js/19.f5710553.js"><link rel="prefetch" href="/blog/assets/js/20.c5857f91.js"><link rel="prefetch" href="/blog/assets/js/22.6ff6077a.js"><link rel="prefetch" href="/blog/assets/js/23.16e4f1c5.js"><link rel="prefetch" href="/blog/assets/js/24.4f0fd2cb.js"><link rel="prefetch" href="/blog/assets/js/25.6c16c5ab.js"><link rel="prefetch" href="/blog/assets/js/26.b65b4e70.js"><link rel="prefetch" href="/blog/assets/js/27.bb918fa1.js"><link rel="prefetch" href="/blog/assets/js/4.b3ed5388.js"><link rel="prefetch" href="/blog/assets/js/5.5bec47c8.js"><link rel="prefetch" href="/blog/assets/js/6.18ba1fe9.js"><link rel="prefetch" href="/blog/assets/js/7.83f31fd9.js"><link rel="prefetch" href="/blog/assets/js/8.a014bfcc.js"><link rel="prefetch" href="/blog/assets/js/9.c6448b60.js">
    <link rel="stylesheet" href="/blog/assets/css/0.styles.0a66d5ca.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-1156296a><div data-v-1156296a><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-1156296a data-v-1156296a><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-4e82dffc data-v-1156296a data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>MLNLP Blog</h3> <p class="description" data-v-4e82dffc data-v-4e82dffc>Blogs on NLP, Machine Learning, Data Mining, and other AI related topics</p> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>Lei Li</span>
            
          <span data-v-4e82dffc>2016 - </span>
          2021
        </a></span></div></div> <div class="hide" data-v-1156296a><header class="navbar" data-v-1156296a><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/blog/" class="home-link router-link-active"><img src="/blog/logo.png" alt="MLNLP Blog" class="logo"> <span class="site-name">MLNLP Blog</span></a> <div class="links"><!----> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/blog/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/categories/ST/" class="nav-link"><i class="undefined"></i>
  ST
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/DL4MT/" class="nav-link"><i class="undefined"></i>
  DL4MT
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/MT/" class="nav-link"><i class="undefined"></i>
  MT
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/NLP/" class="nav-link"><i class="undefined"></i>
  NLP
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/IE/" class="nav-link"><i class="undefined"></i>
  IE
</a></li></ul></div></div><div class="nav-item"><a href="/blog/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/blog/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/lileicc" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  lilei
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-1156296a></div> <aside class="sidebar" data-v-1156296a><div class="personal-info-wrapper" data-v-828910c6 data-v-1156296a><img src="/blog/avatar.png" alt="author-avatar" class="personal-img" data-v-828910c6> <h3 class="name" data-v-828910c6>
    Lei Li
  </h3> <div class="num" data-v-828910c6><div data-v-828910c6><h3 data-v-828910c6>17</h3> <h6 data-v-828910c6>Articles</h6></div> <div data-v-828910c6><h3 data-v-828910c6>29</h3> <h6 data-v-828910c6>Tags</h6></div></div> <ul class="social-links" data-v-828910c6></ul> <hr data-v-828910c6></div> <nav class="nav-links"><div class="nav-item"><a href="/blog/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/blog/categories/ST/" class="nav-link"><i class="undefined"></i>
  ST
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/DL4MT/" class="nav-link"><i class="undefined"></i>
  DL4MT
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/MT/" class="nav-link"><i class="undefined"></i>
  MT
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/NLP/" class="nav-link"><i class="undefined"></i>
  NLP
</a></li><li class="dropdown-item"><!----> <a href="/blog/categories/IE/" class="nav-link"><i class="undefined"></i>
  IE
</a></li></ul></div></div><div class="nav-item"><a href="/blog/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/blog/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="https://github.com/lileicc" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  lilei
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-4e82dffc data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>Revisiting Self-training for Neural Sequence Generation</h3> <!----> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>Lei Li</span>
            
          <span data-v-4e82dffc>2016 - </span>
          2021
        </a></span></div></div> <div data-v-1156296a><main class="page"><section><div class="page-title"><h1 class="title">Revisiting Self-training for Neural Sequence Generation</h1> <div data-v-1ff7123e><i class="iconfont reco-account" data-v-1ff7123e><span data-v-1ff7123e>Zekun Li</span></i> <i class="iconfont reco-date" data-v-1ff7123e><span data-v-1ff7123e>12/5/2021</span></i> <!----> <i class="tags iconfont reco-tag" data-v-1ff7123e><span class="tag-item" data-v-1ff7123e>Self-training</span></i></div></div> <div class="theme-reco-content content__default"><p>Self-training is a very prevalent semi-supervised method. Its key idea is to augment the original labeled dataset with unlabeled data paired with the model's prediction (i.e. the <em>pseudo-parallel</em> data). Self-training has been widely used in classification tasks. However, will it work on sequence generation tasks (e.g. machine translation)? If so, how does it work? This blog introduces a work [1] which investigates these questions and gives the answers.</p> <p>Reading Time: About 10 minutes.</p> <p>Paper：https://arxiv.org/abs/1909.13788</p> <p>Github: https://github.com/jxhe/self-training-text-generation</p> <h2 id="_1-introduction"><a href="#_1-introduction" class="header-anchor">#</a> 1. Introduction</h2> <p><img src="/blog/assets/img/self-training.5f98457e.jpg" alt="image1">
Deep neural networks often require large amounts of labeled data to achieve good performance. However, it is very costly to acquire labels. So what if there is not enough labeled data? Researchers try to fully utilize the unlabeled data to improve the model performance. Self-training is a simple but effective method. As can be seen in the figure above, in self-training, a base model trained with labeled data acts as a “teacher” to label the unannotated data, which is then used to augment the original small training set. Then, a “student” model is trained with this new training set to yield the final model. Self-training is originally designed for classification problems, and it is believed that this method may be effective only when a good fraction of the predictions on unlabeled samples are correct, otherwise errors will be accumulated.</p> <p>However, self-training has not been studied extensively in neural sequence generation tasks like machine translation, where the target output is natural language. So the question arises: can self-training still be useful in this case? Here we introduce a work [1] which investigate the problem and answer the two questions:</p> <ol><li>How does self-training perform in sequence generation tasks like machine translation?</li> <li>If self-training helps improving the baseline, what contributes to its success?</li></ol> <h2 id="_2-case-study-on-machine-translation"><a href="#_2-case-study-on-machine-translation" class="header-anchor">#</a> 2. Case Study on Machine Translation</h2> <p>The authors first analyze the machine translation task, and then perform ablation analysis to understand the contributing factors of the performance gains.</p> <p>They work with the standard WMT 2014 English-German dataset. As a preliminary experiment, they randomly sample 100K sentences from the training set (WMT100K) and use the remaining English sentences as the unlabeled monolingual data. They train with the Base Transformer architecture and use beam search decoding (beam size 5).</p> <p><img src="/blog/assets/img/bar.4e0a6fe6.png" alt="image2">
Green bars in the above figure shows the result of applying self-training for three iterations, which includes:</p> <ol><li>Pseudo-training (PT): the first step of self-training where we train a new model (from scratch) using only the pseudo parallel data generated by the current model</li> <li>Fine-tuning (FT): the fine-tuned system using real parallel data based on the pretrained model from the PT step.</li></ol> <p>It is surprising that the pseudo-training step at the first iteration is able to improve BLEU even if the model is only trained on its own predictions, and fine-tuning further boosts the performance. An explanation is that the added pseudo-parallel data might implicitly change the training trajectory towards a (somehow) better local optimum, given that we train a new model from scratch at each iteration.</p> <table><thead><tr><th style="text-align:left;">Methods</th> <th style="text-align:center;">PT</th> <th style="text-align:center;">FT</th></tr></thead> <tbody><tr><td style="text-align:left;">baseline</td> <td style="text-align:center;">-</td> <td style="text-align:center;">15.6</td></tr> <tr><td style="text-align:left;">baseline (w/o dropout)</td> <td style="text-align:center;">-</td> <td style="text-align:center;">5.2</td></tr> <tr><td style="text-align:left;">ST (beam search, w/ dropout)</td> <td style="text-align:center;">16.5</td> <td style="text-align:center;">17.5</td></tr> <tr><td style="text-align:left;">ST (sampling, w/ dropout)</td> <td style="text-align:center;">16.1</td> <td style="text-align:center;">17.0</td></tr> <tr><td style="text-align:left;">ST (beam search, w/o dropout)</td> <td style="text-align:center;">15.8</td> <td style="text-align:center;">16.3</td></tr> <tr><td style="text-align:left;">ST (sampling, w/o dropout)</td> <td style="text-align:center;">15.5</td> <td style="text-align:center;">16.0</td></tr> <tr><td style="text-align:left;">Noisy ST (beam search, w/o dropout)</td> <td style="text-align:center;">15.8</td> <td style="text-align:center;">17.9</td></tr> <tr><td style="text-align:left;">Noisy ST (beam search, w/ dropout)</td> <td style="text-align:center;"><strong>16.6</strong></td> <td style="text-align:center;"><strong>19.3</strong></td></tr></tbody></table> <h2 id="_3-the-secret-behind-self-training"><a href="#_3-the-secret-behind-self-training" class="header-anchor">#</a> 3. The Secret Behind Self-training</h2> <p>To decode the secret of self-training and understand where the gain comes from, they formulate two hypotheses:</p> <ol><li><p><strong>Decoding Strategy</strong>:
According to this hypothesis, the gains come from the use of beam search for decoding unlabeled data. The above table shows the performance using different decoding strategies. As can be seen, the performance drops by 0.5 BLEU when the decoding strategy is changed to sampling, which implies that beam search does contribute a bit to the performance gains. This phenomenon makes sense intuitively since beam search tends to generate higher-quality pseudo targets than sampling. However, the decoding strategy hypothesis does not fully explain it, as there is still a gain of 1.4 BLEU points over the baseline from sampling decoding with dropout.</p></li> <li><p><strong>Dropout</strong>:
The results in the above table indicate that without dropout the performance of beam search decoding drops by 1.2 BLEU, just 0.7 BLEU higher than the baseline. Moreover, the pseudo-training performance of sampling without dropout is almost the same as the baseline.</p></li></ol> <p>In summary, beam-search decoding contributes only partially to the performance gains, while the implicit perturbation i.e., dropout accounts for most of it. The authors also conduct experiment on a toy dataset to show that noise is beneficial for self-training because it enforces local smoothness for this task, that is, semantically similar inputs are mapped to the same or similar targets.</p> <h2 id="_4-the-proposed-method-noisy-self-training"><a href="#_4-the-proposed-method-noisy-self-training" class="header-anchor">#</a> 4. The Proposed Method: Noisy Self-training</h2> <p>To further improve performance, the authors considers a simple model-agnostic perturbation process - perturbing the input, which is referred to as <em>noisy self-training</em>.
Note that they apply both input perturbation and dropout in the pseudo-training step for noisy ST.
They first apply noisy ST to the WMT100K translation task. Two different perturbation function are tested:</p> <ol><li>Synthetic noise: the input tokens are randomly dropped, masked, and shuffled.</li> <li>Paraphrase: they translate the source English sentences to German and translate it back to obtain a paraphrase as the perturbation.</li></ol> <p>Figure 2 shows the results over three iterations. Noisy ST greatly outperforms the supervised baseline and normal ST, while synthetic noise does not exhibit much difference from paraphrase. Since synthetic noise is much simpler and more general, it is defaulted in Noisy ST.
Table 1 also reports an ablation study of Noisy ST when removing dropout at the pseudo-training step. Noisy ST without dropout improves the baseline by 2.3 BLEU points and is comparable to normal ST with dropout. When combined together, noisy ST with dropout produces another 1.4 BLEU improvement, indicating that the two perturbations are complementary.</p> <h2 id="_5-experiments"><a href="#_5-experiments" class="header-anchor">#</a> 5. Experiments</h2> <h3 id="machine-translation"><a href="#machine-translation" class="header-anchor">#</a> Machine Translation</h3> <p>The author test the proposed noisy ST on a high-resource MT benchmark: WMT14 English-German and a low-resource one: FloRes English-Nepali.</p> <table><thead><tr><th style="text-align:left;">Methods</th> <th style="text-align:center;">WMT14 100K</th> <th style="text-align:center;">WMT14 3.9M</th> <th style="text-align:center;">FloRes En-Origin</th> <th style="text-align:center;">FloRes Ne-Origin</th> <th style="text-align:center;">FloRes Overall</th></tr></thead> <tbody><tr><td style="text-align:left;">baseline</td> <td style="text-align:center;">15.6</td> <td style="text-align:center;">28.3</td> <td style="text-align:center;">6.7</td> <td style="text-align:center;">2.3</td> <td style="text-align:center;">4.8</td></tr> <tr><td style="text-align:left;">BT</td> <td style="text-align:center;">20.5</td> <td style="text-align:center;">-</td> <td style="text-align:center;">8.2</td> <td style="text-align:center;"><strong>4.5</strong></td> <td style="text-align:center;"><strong>6.5</strong></td></tr> <tr><td style="text-align:left;">Noisy ST</td> <td style="text-align:center;"><strong>21.4</strong></td> <td style="text-align:center;"><strong>29.3</strong></td> <td style="text-align:center;"><strong>8.9</strong></td> <td style="text-align:center;">3.5</td> <td style="text-align:center;"><strong>6.5</strong></td></tr></tbody></table> <p>The overall results are shown in the above table. For almost all cases in both datasets, the noisy ST outperforms the baselines by a large margin, and noisy ST still improves the baseline even when this is very weak.</p> <h4 id="comparison-with-back-translation"><a href="#comparison-with-back-translation" class="header-anchor">#</a> Comparison with Back Translation</h4> <p>It can be seen that noisy ST is able to beat BT on WMT100K and on the en-origin test set of FloRes. In contrast, BT is more effective on the ne-origin test set according to BLEU, which is not surprising as the ne-origin test is likely to benefit more from Nepali than English monolingual data.</p> <p><img src="/blog/assets/img/analysis.fd9ddd49.png" alt="image3"></p> <h3 id="analysis"><a href="#analysis" class="header-anchor">#</a> Analysis</h3> <p>The authors analyze the effect of the following three factors on noisy self-training on the WMT14 dataset:</p> <ol><li>Parallel dat size</li> <li>Monolingual dat size</li> <li>Noise level
The result is shown in the above figure. In (a) we see that the performance gain is larger for intermediate value of the size of the parallel dataset, as expected. (b) illustrates that the performance keeps improving as the monolingual data size increases, albeit with diminishing returns.
(c) demonstrates that performance is quite sensitive to noise level, and that intermediate values work best. It is still unclear how to select the noise level a priori, besides the usual hyper-parameter search to maximize BLEU on the validation set.</li></ol> <h2 id="summary"><a href="#summary" class="header-anchor">#</a> Summary</h2> <p>This work revisit self-training for neural sequence generation, especially machine translation task. It is shown that self-training can be an effective method to improve generalization, particularly when labeled data is scarce. Through comprehensive experiments, they prove that noise injected during self-training is critical and thus propose to perturb the input to obtain a variant of self-training, named noisy self-training, which show great power on machine translation and also text summarization tasks.</p> <h2 id="references"><a href="#references" class="header-anchor">#</a> References</h2> <p>[1] He, Junxian, et al. &quot;Revisiting Self-Training for Neural Sequence Generation.&quot; International Conference on Learning Representations. 2019.</p></div></section> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">12/6/2021, 7:52:49 PM</span></div></footer> <!----> <div class="comments-wrapper"><!----></div> <ul class="side-bar sub-sidebar-wrapper" style="width:12rem;" data-v-70334359><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/self-training/#_1-introduction" class="sidebar-link reco-side-_1-introduction" data-v-70334359>1. Introduction</a></li><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/self-training/#_2-case-study-on-machine-translation" class="sidebar-link reco-side-_2-case-study-on-machine-translation" data-v-70334359>2. Case Study on Machine Translation</a></li><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/self-training/#_3-the-secret-behind-self-training" class="sidebar-link reco-side-_3-the-secret-behind-self-training" data-v-70334359>3. The Secret Behind Self-training</a></li><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/self-training/#_4-the-proposed-method-noisy-self-training" class="sidebar-link reco-side-_4-the-proposed-method-noisy-self-training" data-v-70334359>4. The Proposed Method: Noisy Self-training</a></li><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/self-training/#_5-experiments" class="sidebar-link reco-side-_5-experiments" data-v-70334359>5. Experiments</a></li><li class="level-3" data-v-70334359><a href="/blog/blogs/dl4mt/2021/self-training/#machine-translation" class="sidebar-link reco-side-machine-translation" data-v-70334359>Machine Translation</a></li><li class="level-3" data-v-70334359><a href="/blog/blogs/dl4mt/2021/self-training/#analysis" class="sidebar-link reco-side-analysis" data-v-70334359>Analysis</a></li><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/self-training/#summary" class="sidebar-link reco-side-summary" data-v-70334359>Summary</a></li><li class="level-2" data-v-70334359><a href="/blog/blogs/dl4mt/2021/self-training/#references" class="sidebar-link reco-side-references" data-v-70334359>References</a></li></ul></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div></div></div>
    <script src="/blog/assets/js/app.6f4a53e5.js" defer></script><script src="/blog/assets/js/3.9b1d869a.js" defer></script><script src="/blog/assets/js/1.6e4b099c.js" defer></script><script src="/blog/assets/js/21.9965f21d.js" defer></script>
  </body>
</html>
